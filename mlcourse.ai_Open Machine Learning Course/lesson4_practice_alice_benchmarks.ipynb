{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\">\n",
    "## Открытый курс по машинному обучению. Сессия № 2\n",
    "</center>\n",
    "Автор материала: Юрий Исаков и Юрий Кашницкий. Материал распространяется на условиях лицензии [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/). Можно использовать в любых целях (редактировать, поправлять и брать за основу), кроме коммерческих, но с обязательным упоминанием автора материала."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Тема 4. Линейные модели классификации и регрессии\n",
    "## <center>  Практика. Идентификация пользователя с помощью логистической регрессии\n",
    "\n",
    "Тут мы воспроизведем парочку бенчмарков нашего соревнования и вдохновимся побить третий бенчмарк, а также остальных участников. Веб-формы для отправки ответов тут не будет, ориентир – [leaderboard](https://www.kaggle.com/c/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2/leaderboard) соревнования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Загрузка и преобразование данных\n",
    "Зарегистрируйтесь на [Kaggle](www.kaggle.com), если вы не сделали этого раньше, зайдите на [страницу](https://inclass.kaggle.com/c/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2) соревнования и скачайте данные. Первым делом загрузим обучающую и тестовую выборки и посмотрим на данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>time1</th>\n",
       "      <th>site2</th>\n",
       "      <th>time2</th>\n",
       "      <th>site3</th>\n",
       "      <th>time3</th>\n",
       "      <th>site4</th>\n",
       "      <th>time4</th>\n",
       "      <th>site5</th>\n",
       "      <th>time5</th>\n",
       "      <th>...</th>\n",
       "      <th>time6</th>\n",
       "      <th>site7</th>\n",
       "      <th>time7</th>\n",
       "      <th>site8</th>\n",
       "      <th>time8</th>\n",
       "      <th>site9</th>\n",
       "      <th>time9</th>\n",
       "      <th>site10</th>\n",
       "      <th>time10</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21669</th>\n",
       "      <td>56</td>\n",
       "      <td>2013-01-12 08:05:57</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2013-01-12 08:05:57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54843</th>\n",
       "      <td>56</td>\n",
       "      <td>2013-01-12 08:37:23</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2013-01-12 08:37:23</td>\n",
       "      <td>56.0</td>\n",
       "      <td>2013-01-12 09:07:07</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2013-01-12 09:07:09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77292</th>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:13</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:14</td>\n",
       "      <td>951.0</td>\n",
       "      <td>2013-01-12 08:50:15</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:15</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>948.0</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>784.0</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>949.0</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114021</th>\n",
       "      <td>945</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>948.0</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>949.0</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>948.0</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>945.0</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>947.0</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>945.0</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146670</th>\n",
       "      <td>947</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>950.0</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>948.0</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>947.0</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>950.0</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>951.0</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>947.0</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            site1               time1  site2               time2  site3  \\\n",
       "session_id                                                                \n",
       "21669          56 2013-01-12 08:05:57   55.0 2013-01-12 08:05:57    NaN   \n",
       "54843          56 2013-01-12 08:37:23   55.0 2013-01-12 08:37:23   56.0   \n",
       "77292         946 2013-01-12 08:50:13  946.0 2013-01-12 08:50:14  951.0   \n",
       "114021        945 2013-01-12 08:50:17  948.0 2013-01-12 08:50:17  949.0   \n",
       "146670        947 2013-01-12 08:50:20  950.0 2013-01-12 08:50:20  948.0   \n",
       "\n",
       "                         time3  site4               time4  site5  \\\n",
       "session_id                                                         \n",
       "21669                      NaT    NaN                 NaT    NaN   \n",
       "54843      2013-01-12 09:07:07   55.0 2013-01-12 09:07:09    NaN   \n",
       "77292      2013-01-12 08:50:15  946.0 2013-01-12 08:50:15  946.0   \n",
       "114021     2013-01-12 08:50:18  948.0 2013-01-12 08:50:18  945.0   \n",
       "146670     2013-01-12 08:50:20  947.0 2013-01-12 08:50:21  950.0   \n",
       "\n",
       "                         time5  ...               time6  site7  \\\n",
       "session_id                      ...                              \n",
       "21669                      NaT  ...                 NaT    NaN   \n",
       "54843                      NaT  ...                 NaT    NaN   \n",
       "77292      2013-01-12 08:50:16  ... 2013-01-12 08:50:16  948.0   \n",
       "114021     2013-01-12 08:50:18  ... 2013-01-12 08:50:18  947.0   \n",
       "146670     2013-01-12 08:50:21  ... 2013-01-12 08:50:21  946.0   \n",
       "\n",
       "                         time7  site8               time8  site9  \\\n",
       "session_id                                                         \n",
       "21669                      NaT    NaN                 NaT    NaN   \n",
       "54843                      NaT    NaN                 NaT    NaN   \n",
       "77292      2013-01-12 08:50:16  784.0 2013-01-12 08:50:16  949.0   \n",
       "114021     2013-01-12 08:50:19  945.0 2013-01-12 08:50:19  946.0   \n",
       "146670     2013-01-12 08:50:21  951.0 2013-01-12 08:50:22  946.0   \n",
       "\n",
       "                         time9 site10              time10 target  \n",
       "session_id                                                        \n",
       "21669                      NaT    NaN                 NaT      0  \n",
       "54843                      NaT    NaN                 NaT      0  \n",
       "77292      2013-01-12 08:50:17  946.0 2013-01-12 08:50:17      0  \n",
       "114021     2013-01-12 08:50:19  946.0 2013-01-12 08:50:20      0  \n",
       "146670     2013-01-12 08:50:22  947.0 2013-01-12 08:50:22      0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# загрузим обучающую и тестовую выборки\n",
    "train_df = pd.read_csv(\"../../data/alice/train_sessions.csv\", index_col=\"session_id\")\n",
    "test_df = pd.read_csv(\"../../data/alice/test_sessions.csv\", index_col=\"session_id\")\n",
    "\n",
    "# приведем колонки time1, ..., time10 к временному формату\n",
    "times = [\"time%s\" % i for i in range(1, 11)]\n",
    "train_df[times] = train_df[times].apply(pd.to_datetime)\n",
    "test_df[times] = test_df[times].apply(pd.to_datetime)\n",
    "\n",
    "# отсортируем данные по времени\n",
    "train_df = train_df.sort_values(by=\"time1\")\n",
    "\n",
    "# посмотрим на заголовок обучающей выборки\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В обучающей выборке содержатся следующие признаки:\n",
    "    - site1 – индекс первого посещенного сайта в сессии\n",
    "    - time1 – время посещения первого сайта в сессии\n",
    "    - ...\n",
    "    - site10 – индекс 10-го посещенного сайта в сессии\n",
    "    - time10 – время посещения 10-го сайта в сессии\n",
    "    - target – целевая переменная, 1 для сессий Элис, 0 для сессий других пользователей\n",
    "    \n",
    "Сессии пользователей выделены таким образом, что они не могут быть длиннее получаса или 10 сайтов. То есть сессия считается оконченной либо когда пользователь посетил 10 сайтов подряд либо когда сессия заняла по времени более 30 минут.\n",
    "\n",
    "В таблице встречаются пропущенные значения, это значит, что сессия состоит менее, чем из 10 сайтов. Заменим пропущенные значения нулями и приведем признаки к целому типу. Также загрузим словарь сайтов и посмотрим, как он выглядит:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "всего сайтов: 48371\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25075</th>\n",
       "      <td>www.abmecatronique.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13997</th>\n",
       "      <td>groups.live.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42436</th>\n",
       "      <td>majeureliguefootball.wordpress.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30911</th>\n",
       "      <td>cdt46.media.tourinsoft.eu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8104</th>\n",
       "      <td>www.hdwallpapers.eu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     site\n",
       "25075              www.abmecatronique.com\n",
       "13997                     groups.live.com\n",
       "42436  majeureliguefootball.wordpress.com\n",
       "30911           cdt46.media.tourinsoft.eu\n",
       "8104                  www.hdwallpapers.eu"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# приведем колонки site1, ..., site10 к целочисленному формату и заменим пропуски нулями\n",
    "sites = [\"site%s\" % i for i in range(1, 11)]\n",
    "train_df[sites] = train_df[sites].fillna(0).astype(\"int\")\n",
    "test_df[sites] = test_df[sites].fillna(0).astype(\"int\")\n",
    "\n",
    "# загрузим словарик сайтов\n",
    "with open(r\"../../data/site_dic.pkl\", \"rb\") as input_file:\n",
    "    site_dict = pickle.load(input_file)\n",
    "\n",
    "# датафрейм словарика сайтов\n",
    "sites_dict_df = pd.DataFrame(\n",
    "    list(site_dict.keys()), index=list(site_dict.values()), columns=[\"site\"]\n",
    ")\n",
    "print(u\"всего сайтов:\", sites_dict_df.shape[0])\n",
    "sites_dict_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделим целевую переменную и объединим выборки, чтобы вместе привести их к разреженному формату."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# наша целевая переменная\n",
    "y_train = train_df[\"target\"]\n",
    "\n",
    "# объединенная таблица исходных данных\n",
    "full_df = pd.concat([train_df.drop(\"target\", axis=1), test_df])\n",
    "\n",
    "# индекс, по которому будем отделять обучающую выборку от тестовой\n",
    "idx_split = train_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для самой первой модели будем использовать только посещенные сайты в сессии (но не будем обращать внимание на временные признаки). За таким выбором данных для модели стоит такая идея:  *у Элис есть свои излюбленные сайты, и чем чаще вы видим эти сайты в сессии, тем выше вероятность, что это сессия Элис и наоборот.*\n",
    "\n",
    "Подготовим данные, из всей таблицы выберем только признаки `site1, site2, ... , site10`. Напомним, что пропущенные значения заменены нулем. Вот как выглядят первые строки таблицы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>site2</th>\n",
       "      <th>site3</th>\n",
       "      <th>site4</th>\n",
       "      <th>site5</th>\n",
       "      <th>site6</th>\n",
       "      <th>site7</th>\n",
       "      <th>site8</th>\n",
       "      <th>site9</th>\n",
       "      <th>site10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21669</th>\n",
       "      <td>56</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54843</th>\n",
       "      <td>56</td>\n",
       "      <td>55</td>\n",
       "      <td>56</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77292</th>\n",
       "      <td>946</td>\n",
       "      <td>946</td>\n",
       "      <td>951</td>\n",
       "      <td>946</td>\n",
       "      <td>946</td>\n",
       "      <td>945</td>\n",
       "      <td>948</td>\n",
       "      <td>784</td>\n",
       "      <td>949</td>\n",
       "      <td>946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114021</th>\n",
       "      <td>945</td>\n",
       "      <td>948</td>\n",
       "      <td>949</td>\n",
       "      <td>948</td>\n",
       "      <td>945</td>\n",
       "      <td>946</td>\n",
       "      <td>947</td>\n",
       "      <td>945</td>\n",
       "      <td>946</td>\n",
       "      <td>946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146670</th>\n",
       "      <td>947</td>\n",
       "      <td>950</td>\n",
       "      <td>948</td>\n",
       "      <td>947</td>\n",
       "      <td>950</td>\n",
       "      <td>952</td>\n",
       "      <td>946</td>\n",
       "      <td>951</td>\n",
       "      <td>946</td>\n",
       "      <td>947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            site1  site2  site3  site4  site5  site6  site7  site8  site9  \\\n",
       "session_id                                                                  \n",
       "21669          56     55      0      0      0      0      0      0      0   \n",
       "54843          56     55     56     55      0      0      0      0      0   \n",
       "77292         946    946    951    946    946    945    948    784    949   \n",
       "114021        945    948    949    948    945    946    947    945    946   \n",
       "146670        947    950    948    947    950    952    946    951    946   \n",
       "\n",
       "            site10  \n",
       "session_id          \n",
       "21669            0  \n",
       "54843            0  \n",
       "77292          946  \n",
       "114021         946  \n",
       "146670         947  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# табличка с индексами посещенных сайтов в сессии\n",
    "full_sites = full_df[sites]\n",
    "full_sites.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сессии представляют собой последовательность индексов сайтов и данные в таком виде неудобны для линейных методов. В соответствии с нашей гипотезой (у Элис есть излюбленные сайты) надо преобразовать эту таблицу таким образом, чтобы каждому возможному сайту соответствовал свой отдельный признак (колонка), а его значение равнялось бы количеству посещений этого сайта в сессии. Это делается в две строчки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m \u001b[0mcsr_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "Compressed Sparse Row matrix\n",
       "\n",
       "This can be instantiated in several ways:\n",
       "    csr_matrix(D)\n",
       "        with a dense matrix or rank-2 ndarray D\n",
       "\n",
       "    csr_matrix(S)\n",
       "        with another sparse matrix S (equivalent to S.tocsr())\n",
       "\n",
       "    csr_matrix((M, N), [dtype])\n",
       "        to construct an empty matrix with shape (M, N)\n",
       "        dtype is optional, defaulting to dtype='d'.\n",
       "\n",
       "    csr_matrix((data, (row_ind, col_ind)), [shape=(M, N)])\n",
       "        where ``data``, ``row_ind`` and ``col_ind`` satisfy the\n",
       "        relationship ``a[row_ind[k], col_ind[k]] = data[k]``.\n",
       "\n",
       "    csr_matrix((data, indices, indptr), [shape=(M, N)])\n",
       "        is the standard CSR representation where the column indices for\n",
       "        row i are stored in ``indices[indptr[i]:indptr[i+1]]`` and their\n",
       "        corresponding values are stored in ``data[indptr[i]:indptr[i+1]]``.\n",
       "        If the shape parameter is not supplied, the matrix dimensions\n",
       "        are inferred from the index arrays.\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "dtype : dtype\n",
       "    Data type of the matrix\n",
       "shape : 2-tuple\n",
       "    Shape of the matrix\n",
       "ndim : int\n",
       "    Number of dimensions (this is always 2)\n",
       "nnz\n",
       "    Number of stored values, including explicit zeros\n",
       "data\n",
       "    CSR format data array of the matrix\n",
       "indices\n",
       "    CSR format index array of the matrix\n",
       "indptr\n",
       "    CSR format index pointer array of the matrix\n",
       "has_sorted_indices\n",
       "    Whether indices are sorted\n",
       "\n",
       "Notes\n",
       "-----\n",
       "\n",
       "Sparse matrices can be used in arithmetic operations: they support\n",
       "addition, subtraction, multiplication, division, and matrix power.\n",
       "\n",
       "Advantages of the CSR format\n",
       "  - efficient arithmetic operations CSR + CSR, CSR * CSR, etc.\n",
       "  - efficient row slicing\n",
       "  - fast matrix vector products\n",
       "\n",
       "Disadvantages of the CSR format\n",
       "  - slow column slicing operations (consider CSC)\n",
       "  - changes to the sparsity structure are expensive (consider LIL or DOK)\n",
       "\n",
       "Examples\n",
       "--------\n",
       "\n",
       ">>> import numpy as np\n",
       ">>> from scipy.sparse import csr_matrix\n",
       ">>> csr_matrix((3, 4), dtype=np.int8).toarray()\n",
       "array([[0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0]], dtype=int8)\n",
       "\n",
       ">>> row = np.array([0, 0, 1, 2, 2, 2])\n",
       ">>> col = np.array([0, 2, 2, 0, 1, 2])\n",
       ">>> data = np.array([1, 2, 3, 4, 5, 6])\n",
       ">>> csr_matrix((data, (row, col)), shape=(3, 3)).toarray()\n",
       "array([[1, 0, 2],\n",
       "       [0, 0, 3],\n",
       "       [4, 5, 6]])\n",
       "\n",
       ">>> indptr = np.array([0, 2, 3, 6])\n",
       ">>> indices = np.array([0, 2, 2, 0, 1, 2])\n",
       ">>> data = np.array([1, 2, 3, 4, 5, 6])\n",
       ">>> csr_matrix((data, indices, indptr), shape=(3, 3)).toarray()\n",
       "array([[1, 0, 2],\n",
       "       [0, 0, 3],\n",
       "       [4, 5, 6]])\n",
       "\n",
       "Duplicate entries are summed together:\n",
       "\n",
       ">>> row = np.array([0, 1, 2, 0])\n",
       ">>> col = np.array([0, 1, 1, 0])\n",
       ">>> data = np.array([1, 2, 4, 8])\n",
       ">>> csr_matrix((data, (row, col)), shape=(3, 3)).toarray()\n",
       "array([[9, 0, 0],\n",
       "       [0, 2, 0],\n",
       "       [0, 4, 0]])\n",
       "\n",
       "As an example of how to construct a CSR matrix incrementally,\n",
       "the following snippet builds a term-document matrix from texts:\n",
       "\n",
       ">>> docs = [[\"hello\", \"world\", \"hello\"], [\"goodbye\", \"cruel\", \"world\"]]\n",
       ">>> indptr = [0]\n",
       ">>> indices = []\n",
       ">>> data = []\n",
       ">>> vocabulary = {}\n",
       ">>> for d in docs:\n",
       "...     for term in d:\n",
       "...         index = vocabulary.setdefault(term, len(vocabulary))\n",
       "...         indices.append(index)\n",
       "...         data.append(1)\n",
       "...     indptr.append(len(indices))\n",
       "...\n",
       ">>> csr_matrix((data, indices, indptr), dtype=int).toarray()\n",
       "array([[2, 1, 0, 0],\n",
       "       [0, 1, 1, 1]])\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\anaconda3\\lib\\site-packages\\scipy\\sparse\\csr.py\n",
       "\u001b[1;31mType:\u001b[0m           type\n",
       "\u001b[1;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "csr_matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# последовательность с индексами\n",
    "sites_flatten = full_sites.values.flatten()\n",
    "\n",
    "# искомая матрица\n",
    "full_sites_sparse = csr_matrix(\n",
    "    (\n",
    "        [1] * sites_flatten.shape[0],\n",
    "        sites_flatten,\n",
    "        range(0, sites_flatten.shape[0] + 10, 10),\n",
    "    )\n",
    ")[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sparse = full_sites_sparse[:idx_split]\n",
    "X_test_sparse = full_sites_sparse[idx_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((253561, 48371), (253561,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sparse.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Еще один плюс использования разреженных матриц в том, что для них имеются специальные реализации как матричных операций, так и алгоритмов машинного обучения, что подчас позволяет ощутимо ускорить операции за счет особенностей структуры данных. Это касается и логистической регрессии. Вот теперь у нас все готово для построения нашей первой модели.\n",
    "\n",
    "### 2. Построение первой модели\n",
    "\n",
    "Итак, у нас есть алгоритм и данные для него, построим нашу первую модель, воспользовавшись релизацией [логистической регрессии](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) из пакета `sklearn` с параметрами по умолчанию. Первые 90% данных будем использовать для обучения (обучающая выборка отсортирована по времени), а оставшиеся 10% для проверки качества (validation). \n",
    "\n",
    "**Напишите простую функцию, которая будет возвращать качество модели на отложенной выборке, и обучите наш первый классификатор**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_auc_lr_valid(X, y, C=1.0, ratio=0.9, seed=17):\n",
    "    \"\"\"\n",
    "    X, y – выборка\n",
    "    ratio – в каком отношении поделить выборку\n",
    "    C, seed – коэф-т регуляризации и random_state \n",
    "              логистической регрессии\n",
    "    \"\"\"\n",
    "    train_len = int(X.shape[0]*ratio)\n",
    "    X_train_def = X[:train_len]\n",
    "    y_train_def = y[:train_len]\n",
    "    X_test_def = X[train_len:]\n",
    "    y_test_def = y[train_len:]\n",
    "    logit_model = LogisticRegression(C=C, random_state=seed, n_jobs=-1)\n",
    "    logit_model.fit(X_train_def, y_train_def)\n",
    "    logit_pred = logit_model.predict_proba(X_test_def)[:, 1]\n",
    "    return roc_auc_score(y_test_def, logit_pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрите, какой получился ROC AUC на отложенной выборке.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9197951046350004"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_auc_lr_valid(X_train_sparse, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем считать эту модель нашей первой отправной точкой (baseline). Для построения модели для прогноза на тестовой выборке **необходимо обучить модель заново уже на всей обучающей выборке** (пока наша модель обучалась лишь на части данных), что повысит ее обобщающую способность:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для записи прогнозов в файл\n",
    "def write_to_submission_file(\n",
    "    predicted_labels, out_file, target=\"target\", index_label=\"session_id\"\n",
    "):\n",
    "    predicted_df = pd.DataFrame(\n",
    "        predicted_labels,\n",
    "        index=np.arange(1, predicted_labels.shape[0] + 1),\n",
    "        columns=[target],\n",
    "    )\n",
    "    predicted_df.to_csv(out_file, index_label=index_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обучите модель на всей выборке, сделайте прогноз для тестовой выборки и сделайте посылку в соревновании**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(n_jobs=-1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_submit_model = LogisticRegression(n_jobs=-1)\n",
    "first_submit_model.fit(X_train_sparse, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_submit_predict = first_submit_model.predict_proba(X_test_sparse)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write_to_submission_file(first_submit_predict, \"first_submit_predict.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вы выполните эти действия и загрузите ответ на [странице](https://inclass.kaggle.com/c/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2) соревнования, то воспроизведете первый бенчмарк \"Logit\".\n",
    "\n",
    "### 3. Улучшение модели, построение новых признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создайте такой признак, который будет представлять собой число вида ГГГГММ от той даты, когда проходила сессия, например 201407 -- 2014 год и 7 месяц. Таким образом, мы будем учитывать помесячный [линейный тренд](http://people.duke.edu/~rnau/411trend.htm) за весь период предоставленных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feature_train = pd.DataFrame(index=train_df.index)\n",
    "new_feature_test = pd.DataFrame(index=test_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feature_train['year_month'] = train_df['time1'].apply(lambda ts: ts.year*100+ts.month)\n",
    "new_feature_test['year_month'] = test_df['time1'].apply(lambda ts: ts.year*100+ts.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_month</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>201405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            year_month\n",
       "session_id            \n",
       "1               201410\n",
       "2               201407\n",
       "3               201412\n",
       "4               201411\n",
       "5               201405"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_feature_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавьте новый признак, предварительно отмасштабировав его с помощью `StandardScaler`, и снова посчитайте ROC AUC на отложенной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[201410, 201407, 201412, ..., 201405, 201405, 201411]], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_feature_test['year_month'].values.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(new_feature_train['year_month'].values.reshape(-1,1))\n",
    "\n",
    "new_feature_train['year_month_scal'] = scaler.transform(new_feature_train['year_month'].values.reshape(-1,1))\n",
    "new_feature_test['year_month_scal'] = scaler.transform(new_feature_test['year_month'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sparse_new_feat = csr_matrix(hstack([X_train_sparse, new_feature_train[\"year_month_scal\"].values.reshape(-1,1)]))\n",
    "X_test_sparse_new_feat = csr_matrix(hstack([X_test_sparse, new_feature_test[\"year_month_scal\"].values.reshape(-1,1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9198903563591923"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_auc_lr_valid(X_train_sparse_new_feat,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second_submit_model = LogisticRegression(n_jobs=-1)\n",
    "# second_submit_model.fit(X_train_sparse_new_feat, y_train)\n",
    "# second_submit_predict = second_submit_model.predict_proba(X_test_sparse_new_feat)[:, 1]\n",
    "# write_to_submission_file(second_submit_predict, \"second_submit_predict.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Добавьте два новых признака: start_hour и morning.**\n",
    "\n",
    "Признак `start_hour` – это час в который началась сессия (от 0 до 23), а бинарный признак `morning` равен 1, если сессия началась утром и 0, если сессия началась позже (будем считать, что утро это если `start_hour равен` 11 или меньше).\n",
    "\n",
    "**Посчитйте ROC AUC на отложенной выборке для выборки с:**\n",
    "- сайтами, `start_month` и `start_hour`\n",
    "- сайтами, `start_month` и `morning`\n",
    "- сайтами, `start_month`, `start_hour` и `morning`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "session_id\n",
       "21669    2013-01-12 08:05:57\n",
       "54843    2013-01-12 08:37:23\n",
       "77292    2013-01-12 08:50:13\n",
       "114021   2013-01-12 08:50:17\n",
       "146670   2013-01-12 08:50:20\n",
       "Name: time1, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['time1'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2013-02-12 08:33:17'), 5)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['time1'].iloc[500], train_df['time1'].iloc[10].dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feature_train['month'] = train_df['time1'].apply(lambda ts: ts.month)\n",
    "new_feature_test['month'] = test_df['time1'].apply(lambda ts: ts.month)\n",
    "new_feature_train['hour'] = train_df['time1'].apply(lambda ts: ts.hour)\n",
    "new_feature_test['hour'] = test_df['time1'].apply(lambda ts: ts.hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feature_train['morning'] = train_df['time1'].apply(lambda ts: 1 if ts.hour <=11 else 0 )\n",
    "new_feature_test['morning'] = test_df['time1'].apply(lambda ts: 1 if ts.hour <=11 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feature_train['day_of_week'] = train_df['time1'].apply(lambda ts: ts.dayofweek)\n",
    "new_feature_test['day_of_week'] = test_df['time1'].apply(lambda ts: ts.dayofweek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_feature_train['weekend'] = train_df['time1'].apply(lambda ts: ts.dayofweek)\n",
    "# new_feature_test['weekend'] = test_df['time1'].apply(lambda ts: ts.dayofweek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_month</th>\n",
       "      <th>year_month_scal</th>\n",
       "      <th>month</th>\n",
       "      <th>hour</th>\n",
       "      <th>morning</th>\n",
       "      <th>day_of_week</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21669</th>\n",
       "      <td>201301</td>\n",
       "      <td>-1.744405</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54843</th>\n",
       "      <td>201301</td>\n",
       "      <td>-1.744405</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77292</th>\n",
       "      <td>201301</td>\n",
       "      <td>-1.744405</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114021</th>\n",
       "      <td>201301</td>\n",
       "      <td>-1.744405</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146670</th>\n",
       "      <td>201301</td>\n",
       "      <td>-1.744405</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            year_month  year_month_scal  month  hour  morning  day_of_week\n",
       "session_id                                                                \n",
       "21669           201301        -1.744405      1     8        1            5\n",
       "54843           201301        -1.744405      1     8        1            5\n",
       "77292           201301        -1.744405      1     8        1            5\n",
       "114021          201301        -1.744405      1     8        1            5\n",
       "146670          201301        -1.744405      1     8        1            5"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_feature_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(new_feature_train['month'].values.reshape(-1,1))\n",
    "\n",
    "new_feature_train['month_scal'] = scaler.transform(new_feature_train['month'].values.reshape(-1,1))\n",
    "new_feature_test['month_scal'] = scaler.transform(new_feature_test['month'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sparse_new_feat = csr_matrix(hstack([X_train_sparse, new_feature_train[\"month_scal\"].values.reshape(-1,1)]))\n",
    "X_test_sparse_new_feat = csr_matrix(hstack([X_test_sparse, new_feature_test[\"month_scal\"].values.reshape(-1,1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(new_feature_train['hour'].values.reshape(-1,1))\n",
    "\n",
    "new_feature_train['hour_scal'] = scaler.transform(new_feature_train['hour'].values.reshape(-1,1))\n",
    "new_feature_test['hour_scal'] = scaler.transform(new_feature_test['hour'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(new_feature_train['day_of_week'].values.reshape(-1,1))\n",
    "\n",
    "new_feature_train['day_of_week_scal'] = scaler.transform(new_feature_train['day_of_week'].values.reshape(-1,1))\n",
    "new_feature_test['day_of_week_scal'] = scaler.transform(new_feature_test['day_of_week'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>day_of_week_scal</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21669</th>\n",
       "      <td>5</td>\n",
       "      <td>1.682905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54843</th>\n",
       "      <td>5</td>\n",
       "      <td>1.682905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77292</th>\n",
       "      <td>5</td>\n",
       "      <td>1.682905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114021</th>\n",
       "      <td>5</td>\n",
       "      <td>1.682905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146670</th>\n",
       "      <td>5</td>\n",
       "      <td>1.682905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12224</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.179911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164438</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.179911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12221</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.179911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156968</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.179911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204762</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.179911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>253561 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            day_of_week  day_of_week_scal\n",
       "session_id                               \n",
       "21669                 5          1.682905\n",
       "54843                 5          1.682905\n",
       "77292                 5          1.682905\n",
       "114021                5          1.682905\n",
       "146670                5          1.682905\n",
       "...                 ...               ...\n",
       "12224                 2         -0.179911\n",
       "164438                2         -0.179911\n",
       "12221                 2         -0.179911\n",
       "156968                2         -0.179911\n",
       "204762                2         -0.179911\n",
       "\n",
       "[253561 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_feature_train[[\"day_of_week\",\"day_of_week_scal\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sparse_new_feat = csr_matrix(hstack([X_train_sparse, new_feature_train[['year_month_scal',\n",
    "                                                                                \"month_scal\",\n",
    "                                                                                \"hour_scal\",\n",
    "                                                                                'morning',\n",
    "                                                                                'day_of_week_scal']]]))\n",
    "X_test_sparse_new_feat = csr_matrix(hstack([X_test_sparse, new_feature_test[['year_month_scal',\n",
    "                                                                             \"month_scal\",\n",
    "                                                                             \"hour_scal\",\n",
    "                                                                             'morning',\n",
    "                                                                             'day_of_week_scal']]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<82797x48376 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 805927 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_sparse_new_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9686191609636394"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_auc_lr_valid(X_train_sparse_new_feat,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fourth_submit_model = LogisticRegression(n_jobs=-1)\n",
    "# fourth_submit_model.fit(X_train_sparse_new_feat, y_train)\n",
    "# fourth_submit_predict = fourth_submit_model.predict_proba(X_test_sparse_new_feat)[:, 1]\n",
    "# write_to_submission_file(fourth_submit_predict, \"fourth_submit_predict.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4. Подбор коэффицициента регуляризации\n",
    "\n",
    "Итак, мы ввели признаки, которые улучшают качество нашей модели по сравнению с первым бейслайном. Можем ли мы добиться большего значения метрики? После того, как мы сформировали обучающую и тестовую выборки, почти всегда имеет смысл подобрать оптимальные гиперпараметры -- характеристики модели, которые не изменяются во время обучения. Например, на 3 неделе вы проходили решающие деревья, глубина дерева это гиперпараметр, а признак, по которому происходит ветвление и его значение -- нет. В используемой нами логистической регрессии веса каждого признака изменяются и во время обучения находится их оптимальные значения, а коэффициент регуляризации остается постоянным. Это тот гиперпараметр, который мы сейчас будем оптимизировать.\n",
    "\n",
    "Посчитайте качество на отложенной выборке с коэффициентом регуляризации, который по умолчанию `C=1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_auc_lr_valid_2(X, y, C, ratio=0.75, seed=17):\n",
    "    \"\"\"\n",
    "    X, y – выборка\n",
    "    ratio – в каком отношении поделить выборку\n",
    "    C, seed – коэф-т регуляризации и random_state \n",
    "              логистической регрессии\n",
    "    \"\"\"\n",
    "    train_len = int(X.shape[0]*ratio)\n",
    "    X_train_def = X[:train_len]\n",
    "    y_train_def = y[:train_len]\n",
    "    X_test_def = X[train_len:]\n",
    "    y_test_def = y[train_len:]\n",
    "    logit_model = LogisticRegression(C=C, random_state=seed, n_jobs=-1)\n",
    "    logit_model.fit(X_train_def, y_train_def)\n",
    "    logit_pred = logit_model.predict_proba(X_test_def)[:, 1]\n",
    "    return roc_auc_score(y_test_def, logit_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9420665563395398"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_auc_lr_valid_2(X_train_sparse_new_feat,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.00000000e-03 = 0.9610654426140817\n",
    "# 2.78255940e-03 = 0.9668040948278465\n",
    "# 7.74263683e-03 = 0.9708283669597582\n",
    "# 2.15443469e-02 = 0.9734217498783313\n",
    "\n",
    "\n",
    "# 5.99484250e-02 = 0.9739842030072373\n",
    "\n",
    "\n",
    "# 1.66810054e-01 = 0.9728159730650465\n",
    "# 4.64158883e-01 = 0.9705558957043435\n",
    "# 1.29154967e+00 = 0.9681576957958817\n",
    "# 3.59381366e+00 = 0.9658025176645908\n",
    "# 1.00000000e+01 = 0.9630605963995754\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постараемся побить этот результат за счет оптимизации коэффициента регуляризации. Возьмем набор возможных значений C и для каждого из них посчитаем значение метрики на отложенной выборке.\n",
    "\n",
    "Найдите `C` из `np.logspace(-3, 1, 10)`, при котором ROC AUC на отложенной выборке максимален. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00000000e-03, 2.78255940e-03, 7.74263683e-03, 2.15443469e-02,\n",
       "       5.99484250e-02, 1.66810054e-01, 4.64158883e-01, 1.29154967e+00,\n",
       "       3.59381366e+00, 1.00000000e+01])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logspace(-3, 1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {\"C\":np.logspace(-3, 1, 10), \"penalty\":[\"l1\",\"l2\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg_cv=GridSearchCV(logreg,grid,cv=5)\n",
    "logreg_cv.fit(X_train_sparse_new_feat,y_train)\n",
    "\n",
    "print(\"tuned hpyerparameters :(best parameters) \",logreg_cv.best_params_)\n",
    "print(\"accuracy :\",logreg_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец, обучите модель с найденным оптимальным значением коэффициента регуляризации и с построенными признаками `start_hour`, `start_month` и `morning`. Если вы все сделали правильно и загрузите это решение, то повторите второй бенчмарк соревнования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fifth_submit_model = LogisticRegression(n_jobs=-1, C=5.99484250e-02)\n",
    "# fifth_submit_model.fit(X_train_sparse_new_feat, y_train)\n",
    "# fifth_submit_predict = fifth_submit_model.predict_proba(X_test_sparse_new_feat)[:, 1]\n",
    "# write_to_submission_file(fifth_submit_predict, \"fifth_submit_predict.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skf = StratifiedKFold(n_splits=7, shuffle=True, random_state=17)\n",
    "\n",
    "# c_values = np.logspace(-3, 3, 50)\n",
    "\n",
    "# logit_searcher = LogisticRegressionCV(Cs=c_values, cv=skf, verbose=1, n_jobs=-1)\n",
    "# logit_searcher.fit(X_train_sparse_new_feat, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logit_searcher.C_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eighth_submit_predict=logit_searcher.predict_proba(X_test_sparse_new_feat)[:, 1]\n",
    "# write_to_submission_file(eighth_submit_predict, \"eighth_submit_predict.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seventh_submit_predict=logit_searcher.predict_proba(X_test_sparse_new_feat)[:, 1]\n",
    "# write_to_submission_file(seventh_submit_predict, \"seventh_submit_predict.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sixth_submit_model = LogisticRegression(n_jobs=-1, C=3.59381366)\n",
    "# sixth_submit_model.fit(X_train_sparse_new_feat, y_train)\n",
    "# sixth_submit_predict = sixth_submit_model.predict_proba(X_test_sparse_new_feat)[:, 1]\n",
    "# write_to_submission_file(sixth_submit_predict, \"sixth_submit_predict.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logit_searcher' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [54]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mlogit_searcher\u001b[49m\u001b[38;5;241m.\u001b[39mscores_\n",
      "\u001b[1;31mNameError\u001b[0m: name 'logit_searcher' is not defined"
     ]
    }
   ],
   "source": [
    "logit_searcher.scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timedelta('0 days 00:20:02')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['time2'].iloc[300] - train_df['time1'].iloc[300]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(c_values, np.mean(logit_searcher.scores_[1], axis=0))\n",
    "plt.xlabel(\"C\")\n",
    "plt.ylabel(\"Mean CV-accuracy\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(c_values, np.mean(logit_searcher.scores_[1], axis=0))\n",
    "plt.xlabel(\"C\")\n",
    "plt.ylabel(\"Mean CV-accuracy\")\n",
    "plt.xlim((0, 20));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feature_train['first_session_duration'] = (train_df['time2']-train_df['time1']).apply(lambda ts: ts.seconds)\n",
    "new_feature_test['first_session_duration'] = (test_df['time2']-test_df['time1']).apply(lambda ts: ts.seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feature_train['first_session_duration_scal'] = scaler.transform(new_feature_train['first_session_duration'].values.reshape(-1,1))\n",
    "new_feature_test['first_session_duration_scal'] = scaler.transform(new_feature_test['first_session_duration'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sparse_new_feat_sec = csr_matrix(hstack([X_train_sparse_new_feat, new_feature_train[['first_session_duration_scal']]]))\n",
    "X_test_sparse_new_feat_sec = csr_matrix(hstack([X_test_sparse_new_feat, new_feature_test[['first_session_duration_scal']]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [96]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mget_auc_lr_valid_2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_sparse_new_feat_sec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5.99484250e-02\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [95]\u001b[0m, in \u001b[0;36mget_auc_lr_valid_2\u001b[1;34m(X, y, C, ratio, seed)\u001b[0m\n\u001b[0;32m     12\u001b[0m y_test_def \u001b[38;5;241m=\u001b[39m y[train_len:]\n\u001b[0;32m     13\u001b[0m logit_model \u001b[38;5;241m=\u001b[39m LogisticRegression(C\u001b[38;5;241m=\u001b[39mC, random_state\u001b[38;5;241m=\u001b[39mseed, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m \u001b[43mlogit_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_def\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_def\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m logit_pred \u001b[38;5;241m=\u001b[39m logit_model\u001b[38;5;241m.\u001b[39mpredict_proba(X_test_def)[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m roc_auc_score(y_test_def, logit_pred)\n",
      "File \u001b[1;32mC:\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1508\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1506\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[1;32m-> 1508\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1510\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1512\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1513\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1514\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mliblinear\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msag\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaga\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1515\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1516\u001b[0m check_classification_targets(y)\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n",
      "File \u001b[1;32mC:\\anaconda3\\lib\\site-packages\\sklearn\\base.py:581\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    579\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 581\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    582\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mC:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:964\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    961\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    962\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my cannot be None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 964\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    979\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric)\n\u001b[0;32m    981\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32mC:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:720\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sp\u001b[38;5;241m.\u001b[39missparse(array):\n\u001b[0;32m    719\u001b[0m     _ensure_no_complex_data(array)\n\u001b[1;32m--> 720\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43m_ensure_sparse_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    721\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    723\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    724\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    725\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    726\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    727\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    729\u001b[0m     \u001b[38;5;66;03m# If np.array(..) gives ComplexWarning, then we convert the warning\u001b[39;00m\n\u001b[0;32m    730\u001b[0m     \u001b[38;5;66;03m# to an error. This is needed because specifying a non complex\u001b[39;00m\n\u001b[0;32m    731\u001b[0m     \u001b[38;5;66;03m# dtype to the function converts complex to real dtype,\u001b[39;00m\n\u001b[0;32m    732\u001b[0m     \u001b[38;5;66;03m# thereby passing the test made in the lines following the scope\u001b[39;00m\n\u001b[0;32m    733\u001b[0m     \u001b[38;5;66;03m# of warnings context manager.\u001b[39;00m\n\u001b[0;32m    734\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n",
      "File \u001b[1;32mC:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:479\u001b[0m, in \u001b[0;36m_ensure_sparse_format\u001b[1;34m(spmatrix, accept_sparse, dtype, copy, force_all_finite, accept_large_sparse)\u001b[0m\n\u001b[0;32m    474\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    475\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt check \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m sparse matrix for nan or inf.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m spmatrix\u001b[38;5;241m.\u001b[39mformat,\n\u001b[0;32m    476\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m    477\u001b[0m         )\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 479\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspmatrix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m spmatrix\n",
      "File \u001b[1;32mC:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:114\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    108\u001b[0m         allow_nan\n\u001b[0;32m    109\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39misinf(X)\u001b[38;5;241m.\u001b[39many()\n\u001b[0;32m    110\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nan\n\u001b[0;32m    111\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(X)\u001b[38;5;241m.\u001b[39mall()\n\u001b[0;32m    112\u001b[0m     ):\n\u001b[0;32m    113\u001b[0m         type_err \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfinity\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m allow_nan \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaN, infinity\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    115\u001b[0m             msg_err\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    116\u001b[0m                 type_err, msg_dtype \u001b[38;5;28;01mif\u001b[39;00m msg_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m    117\u001b[0m             )\n\u001b[0;32m    118\u001b[0m         )\n\u001b[0;32m    119\u001b[0m \u001b[38;5;66;03m# for object dtype data, we only check for NaNs (GH-13254)\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nan:\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "get_auc_lr_valid_2(X_train_sparse_new_feat_sec, y_train, C=5.99484250e-02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    81308\n",
       "True      1489\n",
       "Name: first_session_duration, dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_feature_test['first_session_duration'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feature_test['first_session_duration'].fillna(-1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    82797\n",
       "Name: first_session_duration, dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_feature_test['first_session_duration'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feature_train['first_session_duration'].fillna(-1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    253561\n",
       "Name: first_session_duration, dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_feature_train['first_session_duration'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feature_train['first_session_duration_scal'] = scaler.transform(new_feature_train['first_session_duration'].values.reshape(-1,1))\n",
    "new_feature_test['first_session_duration_scal'] = scaler.transform(new_feature_test['first_session_duration'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sparse_new_feat_sec = csr_matrix(hstack([X_train_sparse_new_feat, new_feature_train[['first_session_duration_scal']]]))\n",
    "X_test_sparse_new_feat_sec = csr_matrix(hstack([X_test_sparse_new_feat, new_feature_test[['first_session_duration_scal']]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9449123499447211"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_auc_lr_valid_2(X_train_sparse_new_feat_sec, y_train, C=5.99484250e-02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "ninth_submit_model = LogisticRegression(n_jobs=-1, C=5.99484250e-02)\n",
    "ninth_submit_model.fit(X_train_sparse_new_feat_sec, y_train)\n",
    "ninth_submit_predict = ninth_submit_model.predict_proba(X_test_sparse_new_feat_sec)[:, 1]\n",
    "write_to_submission_file(ninth_submit_predict, \"ninth_submit_predict.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  7.0min remaining: 10.4min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  7.1min finished\n",
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=array([1.00000000e-03, 1.32571137e-03, 1.75751062e-03, 2.32995181e-03,\n",
       "       3.08884360e-03, 4.09491506e-03, 5.42867544e-03, 7.19685673e-03,\n",
       "       9.54095476e-03, 1.26485522e-02, 1.67683294e-02, 2.22299648e-02,\n",
       "       2.94705170e-02, 3.90693994e-02, 5.17947468e-02, 6.86648845e-02,\n",
       "       9.10298178e-02, 1.20679264e-01, 1.59985872e-01, 2.12095089e-01,\n",
       "       2.81176870e-01, 3.72...\n",
       "       8.28642773e+00, 1.09854114e+01, 1.45634848e+01, 1.93069773e+01,\n",
       "       2.55954792e+01, 3.39322177e+01, 4.49843267e+01, 5.96362332e+01,\n",
       "       7.90604321e+01, 1.04811313e+02, 1.38949549e+02, 1.84206997e+02,\n",
       "       2.44205309e+02, 3.23745754e+02, 4.29193426e+02, 5.68986603e+02,\n",
       "       7.54312006e+02, 1.00000000e+03]),\n",
       "                     cv=StratifiedKFold(n_splits=5, random_state=17, shuffle=True),\n",
       "                     n_jobs=-1, verbose=1)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=17)\n",
    "\n",
    "c_values = np.logspace(-3, 3,)\n",
    "\n",
    "logit_searcher = LogisticRegressionCV(Cs=c_values, cv=skf, verbose=1, n_jobs=-1)\n",
    "logit_searcher.fit(X_train_sparse_new_feat_sec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.25055193])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_searcher.C_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(c_values, np.mean(logit_searcher.scores_[1], axis=0))\n",
    "plt.xlabel(\"C\")\n",
    "plt.ylabel(\"Mean CV-accuracy\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9364945286515856"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_auc_lr_valid_2(X_train_sparse_new_feat_sec, y_train, 6.25055193)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "tenth_submit_predict=logit_searcher.predict_proba(X_test_sparse_new_feat_sec)[:, 1]\n",
    "write_to_submission_file(tenth_submit_predict, \"tenth_submit_predict.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_auc_lr_valid_3_knn(X, y, ratio=0.75):\n",
    "    \"\"\"\n",
    "    X, y – выборка\n",
    "    ratio – в каком отношении поделить выборку\n",
    "    C, seed – коэф-т регуляризации и random_state \n",
    "              логистической регрессии\n",
    "    \"\"\"\n",
    "    train_len = int(X.shape[0]*ratio)\n",
    "    X_train_def = X[:train_len]\n",
    "    y_train_def = y[:train_len]\n",
    "    X_test_def = X[train_len:]\n",
    "    y_test_def = y[train_len:]\n",
    "    knn_model = KNeighborsClassifier(n_jobs=-1)\n",
    "    knn_model.fit(X_train_def, y_train_def)\n",
    "    knn_pred = knn_model.predict_proba(X_test_def)[:, 1]\n",
    "    return roc_auc_score(y_test_def, knn_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6662797831310285"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_auc_lr_valid_3_knn(X_train_sparse_new_feat_sec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
